2025-02-25 23:37:54,649 - INFO - ======== Starting Model Training ========
2025-02-25 23:37:54,649 - INFO - Loading dataset...
2025-02-25 23:37:55,406 - INFO - Dataset loaded successfully!
2025-02-25 23:37:55,407 - INFO - Initializing the model...
2025-02-25 23:37:55,486 - INFO - Model initialized with 1,077,445 trainable parameters.
2025-02-25 23:37:55,489 - INFO - Model Architecture: 
MobileNetV2ForCIFAR8M(
  (mobilenet_v2): MobileNetV2(
    (features): Sequential(
      (0): Conv2dNormActivation(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (classifier): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=2048, out_features=512, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.9, inplace=False)
      (4): Linear(in_features=512, out_features=5, bias=True)
    )
  )
)
2025-02-25 23:37:55,490 - INFO - Starting training for 35 epochs...
2025-02-25 23:37:56,184 - INFO - Tr_Loss: 1.6692, val_loss: 1.5504, Tr_acc: 21.685144124168513, val_ac: 36.81489141675284
2025-02-25 23:37:56,578 - INFO - Tr_Loss: 1.5738, val_loss: 1.4890, Tr_acc: 28.824833702882483, val_ac: 49.12099276111686
2025-02-25 23:37:56,939 - INFO - Tr_Loss: 1.4963, val_loss: 1.4357, Tr_acc: 35.29933481152993, val_ac: 54.39503619441572
2025-02-25 23:37:57,293 - INFO - Tr_Loss: 1.4433, val_loss: 1.3872, Tr_acc: 38.8470066518847, val_ac: 57.39400206825233
2025-02-25 23:37:57,640 - INFO - Tr_Loss: 1.3984, val_loss: 1.3419, Tr_acc: 43.28159645232816, val_ac: 58.014477766287484
2025-02-25 23:37:57,985 - INFO - Tr_Loss: 1.3425, val_loss: 1.2975, Tr_acc: 48.38137472283814, val_ac: 59.4622543950362
2025-02-25 23:37:58,331 - INFO - Tr_Loss: 1.3040, val_loss: 1.2536, Tr_acc: 50.90909090909091, val_ac: 59.97931747673216
2025-02-25 23:37:58,674 - INFO - Tr_Loss: 1.2522, val_loss: 1.2115, Tr_acc: 51.44124168514412, val_ac: 61.220268872802485
2025-02-25 23:37:59,015 - INFO - Tr_Loss: 1.2203, val_loss: 1.1717, Tr_acc: 53.65853658536585, val_ac: 62.047569803516026
2025-02-25 23:37:59,348 - INFO - Tr_Loss: 1.1834, val_loss: 1.1341, Tr_acc: 56.09756097560975, val_ac: 63.081695966907965
2025-02-25 23:37:59,694 - INFO - Tr_Loss: 1.1381, val_loss: 1.0985, Tr_acc: 59.15742793791574, val_ac: 64.83971044467425
2025-02-25 23:38:00,036 - INFO - Tr_Loss: 1.0819, val_loss: 1.0650, Tr_acc: 61.1529933481153, val_ac: 65.14994829369184
2025-02-25 23:38:00,369 - INFO - Tr_Loss: 1.0610, val_loss: 1.0343, Tr_acc: 61.24168514412417, val_ac: 65.77042399172699
2025-02-25 23:38:00,717 - INFO - Tr_Loss: 1.0206, val_loss: 1.0061, Tr_acc: 63.28159645232816, val_ac: 67.01137538779732
2025-02-25 23:38:01,056 - INFO - Tr_Loss: 0.9917, val_loss: 0.9804, Tr_acc: 65.14412416851441, val_ac: 67.63185108583247
2025-02-25 23:38:01,395 - INFO - Tr_Loss: 0.9505, val_loss: 0.9564, Tr_acc: 66.38580931263859, val_ac: 67.63185108583247
2025-02-25 23:38:01,733 - INFO - Tr_Loss: 0.9420, val_loss: 0.9350, Tr_acc: 66.0310421286031, val_ac: 68.25232678386763
2025-02-25 23:38:02,069 - INFO - Tr_Loss: 0.9217, val_loss: 0.9158, Tr_acc: 66.56319290465632, val_ac: 69.18304033092038
2025-02-25 23:38:02,406 - INFO - Tr_Loss: 0.8891, val_loss: 0.8979, Tr_acc: 68.78048780487805, val_ac: 69.80351602895553
2025-02-25 23:38:02,743 - INFO - Tr_Loss: 0.8567, val_loss: 0.8810, Tr_acc: 70.33259423503326, val_ac: 69.90692864529473
2025-02-25 23:38:03,074 - INFO - Tr_Loss: 0.8505, val_loss: 0.8652, Tr_acc: 70.06651884700665, val_ac: 70.11375387797311
2025-02-25 23:38:03,419 - INFO - Tr_Loss: 0.8263, val_loss: 0.8505, Tr_acc: 71.35254988913526, val_ac: 70.52740434332989
2025-02-25 23:38:03,751 - INFO - Tr_Loss: 0.8068, val_loss: 0.8375, Tr_acc: 71.44124168514412, val_ac: 71.45811789038262
2025-02-25 23:38:04,096 - INFO - Tr_Loss: 0.7774, val_loss: 0.8255, Tr_acc: 73.52549889135256, val_ac: 71.97518097207859
2025-02-25 23:38:04,431 - INFO - Tr_Loss: 0.7710, val_loss: 0.8136, Tr_acc: 72.46119733924613, val_ac: 72.28541882109617
2025-02-25 23:38:04,773 - INFO - Tr_Loss: 0.7738, val_loss: 0.8024, Tr_acc: 73.12638580931264, val_ac: 72.28541882109617
2025-02-25 23:38:05,110 - INFO - Tr_Loss: 0.7331, val_loss: 0.7923, Tr_acc: 74.14634146341463, val_ac: 72.18200620475697
2025-02-25 23:38:05,442 - INFO - Tr_Loss: 0.7250, val_loss: 0.7827, Tr_acc: 75.3880266075388, val_ac: 72.59565667011375
2025-02-25 23:38:05,789 - INFO - Tr_Loss: 0.7073, val_loss: 0.7740, Tr_acc: 75.2549889135255, val_ac: 72.90589451913134
2025-02-25 23:38:06,131 - INFO - Tr_Loss: 0.6911, val_loss: 0.7665, Tr_acc: 76.49667405764967, val_ac: 72.69906928645295
2025-02-25 23:38:06,469 - INFO - Tr_Loss: 0.6756, val_loss: 0.7590, Tr_acc: 76.71840354767184, val_ac: 73.11271975180972
2025-02-25 23:38:06,815 - INFO - Tr_Loss: 0.6675, val_loss: 0.7514, Tr_acc: 77.87139689578714, val_ac: 73.4229576008273
2025-02-25 23:38:07,151 - INFO - Tr_Loss: 0.6405, val_loss: 0.7441, Tr_acc: 78.40354767184036, val_ac: 73.52637021716649
2025-02-25 23:38:07,491 - INFO - Tr_Loss: 0.6418, val_loss: 0.7378, Tr_acc: 79.06873614190687, val_ac: 73.73319544984489
2025-02-25 23:38:07,827 - INFO - Tr_Loss: 0.6162, val_loss: 0.7312, Tr_acc: 79.51219512195122, val_ac: 74.25025853154085
2025-02-25 23:38:07,827 - INFO - Saving trained model and training results...
2025-02-25 23:38:08,225 - INFO - Starting model evaluation...
2025-02-25 23:38:08,250 - INFO - Test Loss: 0.6627
2025-02-25 23:38:08,251 - INFO - Test Accuracy: 79.60%
2025-02-25 23:38:08,251 - INFO - ======== Model Training Completed! ========
