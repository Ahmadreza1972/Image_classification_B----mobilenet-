2025-02-25 23:50:50,839 - INFO - ======== Starting Model Training ========
2025-02-25 23:50:50,839 - INFO - Loading dataset...
2025-02-25 23:50:51,585 - INFO - Dataset loaded successfully!
2025-02-25 23:50:51,585 - INFO - Initializing the model...
2025-02-25 23:50:51,665 - INFO - Model initialized with 1,077,445 trainable parameters.
2025-02-25 23:50:51,668 - INFO - Model Architecture: 
MobileNetV2ForCIFAR8M(
  (mobilenet_v2): MobileNetV2(
    (features): Sequential(
      (0): Conv2dNormActivation(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (classifier): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=2048, out_features=512, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.9, inplace=False)
      (4): Linear(in_features=512, out_features=5, bias=True)
    )
  )
)
2025-02-25 23:50:51,669 - INFO - Starting training for 100 epochs...
2025-02-25 23:50:52,416 - INFO - Tr_Loss: 1.6828, val_loss: 1.6031, Tr_acc: 19.938107869142353, val_ac: 25.97938144329897
2025-02-25 23:50:52,816 - INFO - Tr_Loss: 1.6617, val_loss: 1.5871, Tr_acc: 21.308576480990276, val_ac: 29.38144329896907
2025-02-25 23:50:53,196 - INFO - Tr_Loss: 1.6332, val_loss: 1.5724, Tr_acc: 23.342175066312997, val_ac: 33.91752577319588
2025-02-25 23:50:53,554 - INFO - Tr_Loss: 1.6113, val_loss: 1.5585, Tr_acc: 25.641025641025642, val_ac: 36.70103092783505
2025-02-25 23:50:53,930 - INFO - Tr_Loss: 1.5913, val_loss: 1.5452, Tr_acc: 25.906277630415563, val_ac: 37.628865979381445
2025-02-25 23:50:54,293 - INFO - Tr_Loss: 1.5905, val_loss: 1.5326, Tr_acc: 26.79045092838196, val_ac: 38.865979381443296
2025-02-25 23:50:54,674 - INFO - Tr_Loss: 1.5684, val_loss: 1.5208, Tr_acc: 28.868258178603007, val_ac: 39.896907216494846
2025-02-25 23:50:55,034 - INFO - Tr_Loss: 1.5516, val_loss: 1.5094, Tr_acc: 30.592396109637487, val_ac: 40.51546391752577
2025-02-25 23:50:55,390 - INFO - Tr_Loss: 1.5298, val_loss: 1.4985, Tr_acc: 32.89124668435013, val_ac: 41.23711340206186
2025-02-25 23:50:55,759 - INFO - Tr_Loss: 1.5076, val_loss: 1.4878, Tr_acc: 34.61538461538461, val_ac: 41.34020618556701
2025-02-25 23:50:56,122 - INFO - Tr_Loss: 1.5072, val_loss: 1.4777, Tr_acc: 33.819628647214856, val_ac: 42.2680412371134
2025-02-25 23:50:56,488 - INFO - Tr_Loss: 1.4893, val_loss: 1.4677, Tr_acc: 35.632183908045974, val_ac: 43.402061855670105
2025-02-25 23:50:56,842 - INFO - Tr_Loss: 1.4895, val_loss: 1.4582, Tr_acc: 35.36693191865606, val_ac: 43.81443298969072
2025-02-25 23:50:57,195 - INFO - Tr_Loss: 1.4638, val_loss: 1.4489, Tr_acc: 37.8868258178603, val_ac: 44.63917525773196
2025-02-25 23:50:57,567 - INFO - Tr_Loss: 1.4570, val_loss: 1.4400, Tr_acc: 37.84261715296198, val_ac: 44.845360824742265
2025-02-25 23:50:57,936 - INFO - Tr_Loss: 1.4403, val_loss: 1.4315, Tr_acc: 39.47833775419982, val_ac: 45.25773195876289
2025-02-25 23:50:58,306 - INFO - Tr_Loss: 1.4474, val_loss: 1.4231, Tr_acc: 38.41732979664014, val_ac: 45.56701030927835
2025-02-25 23:50:58,662 - INFO - Tr_Loss: 1.4195, val_loss: 1.4149, Tr_acc: 40.274093722369585, val_ac: 46.18556701030928
2025-02-25 23:50:59,028 - INFO - Tr_Loss: 1.4180, val_loss: 1.4067, Tr_acc: 40.5393457117595, val_ac: 46.391752577319586
2025-02-25 23:50:59,392 - INFO - Tr_Loss: 1.4117, val_loss: 1.3990, Tr_acc: 40.36251105216623, val_ac: 46.70103092783505
2025-02-25 23:50:59,747 - INFO - Tr_Loss: 1.4018, val_loss: 1.3919, Tr_acc: 41.06984969053934, val_ac: 47.21649484536083
2025-02-25 23:51:00,120 - INFO - Tr_Loss: 1.3759, val_loss: 1.3845, Tr_acc: 42.92661361626879, val_ac: 47.01030927835052
2025-02-25 23:51:00,473 - INFO - Tr_Loss: 1.3806, val_loss: 1.3774, Tr_acc: 42.61715296198055, val_ac: 47.628865979381445
2025-02-25 23:51:00,839 - INFO - Tr_Loss: 1.3581, val_loss: 1.3706, Tr_acc: 45.04862953138815, val_ac: 47.93814432989691
2025-02-25 23:51:01,201 - INFO - Tr_Loss: 1.3519, val_loss: 1.3640, Tr_acc: 44.47391688770999, val_ac: 48.45360824742268
2025-02-25 23:51:01,581 - INFO - Tr_Loss: 1.3425, val_loss: 1.3574, Tr_acc: 44.783377541998235, val_ac: 48.76288659793814
2025-02-25 23:51:01,959 - INFO - Tr_Loss: 1.3298, val_loss: 1.3510, Tr_acc: 47.03801945181255, val_ac: 49.381443298969074
2025-02-25 23:51:02,337 - INFO - Tr_Loss: 1.3253, val_loss: 1.3446, Tr_acc: 46.242263483642795, val_ac: 49.58762886597938
2025-02-25 23:51:02,699 - INFO - Tr_Loss: 1.3309, val_loss: 1.3386, Tr_acc: 46.286472148541115, val_ac: 49.48453608247423
2025-02-25 23:51:03,063 - INFO - Tr_Loss: 1.3161, val_loss: 1.3327, Tr_acc: 46.50751547303271, val_ac: 49.48453608247423
2025-02-25 23:51:03,443 - INFO - Tr_Loss: 1.2878, val_loss: 1.3269, Tr_acc: 49.46949602122016, val_ac: 49.48453608247423
2025-02-25 23:51:03,812 - INFO - Tr_Loss: 1.2961, val_loss: 1.3209, Tr_acc: 48.762157382847036, val_ac: 50.20618556701031
2025-02-25 23:51:04,178 - INFO - Tr_Loss: 1.2915, val_loss: 1.3150, Tr_acc: 48.894783377542, val_ac: 50.618556701030926
2025-02-25 23:51:04,553 - INFO - Tr_Loss: 1.2676, val_loss: 1.3092, Tr_acc: 49.46949602122016, val_ac: 50.618556701030926
2025-02-25 23:51:04,924 - INFO - Tr_Loss: 1.2736, val_loss: 1.3035, Tr_acc: 49.3368700265252, val_ac: 51.649484536082475
2025-02-25 23:51:05,302 - INFO - Tr_Loss: 1.2771, val_loss: 1.2980, Tr_acc: 49.29266136162688, val_ac: 52.06185567010309
2025-02-25 23:51:05,659 - INFO - Tr_Loss: 1.2641, val_loss: 1.2925, Tr_acc: 49.46949602122016, val_ac: 52.2680412371134
2025-02-25 23:51:06,023 - INFO - Tr_Loss: 1.2576, val_loss: 1.2873, Tr_acc: 49.95579133510168, val_ac: 52.371134020618555
2025-02-25 23:51:06,375 - INFO - Tr_Loss: 1.2347, val_loss: 1.2818, Tr_acc: 51.9893899204244, val_ac: 52.577319587628864
2025-02-25 23:51:06,748 - INFO - Tr_Loss: 1.2360, val_loss: 1.2767, Tr_acc: 51.41467727674624, val_ac: 52.88659793814433
2025-02-25 23:51:07,114 - INFO - Tr_Loss: 1.2256, val_loss: 1.2717, Tr_acc: 52.87356321839081, val_ac: 53.50515463917526
2025-02-25 23:51:07,481 - INFO - Tr_Loss: 1.2158, val_loss: 1.2663, Tr_acc: 52.829354553492486, val_ac: 53.50515463917526
2025-02-25 23:51:07,904 - INFO - Tr_Loss: 1.2138, val_loss: 1.2611, Tr_acc: 53.00618921308576, val_ac: 53.402061855670105
2025-02-25 23:51:08,279 - INFO - Tr_Loss: 1.2030, val_loss: 1.2560, Tr_acc: 53.5366931918656, val_ac: 53.71134020618557
2025-02-25 23:51:08,682 - INFO - Tr_Loss: 1.2071, val_loss: 1.2513, Tr_acc: 52.43147656940761, val_ac: 53.608247422680414
2025-02-25 23:51:09,059 - INFO - Tr_Loss: 1.1896, val_loss: 1.2463, Tr_acc: 54.02298850574713, val_ac: 53.402061855670105
2025-02-25 23:51:09,448 - INFO - Tr_Loss: 1.1738, val_loss: 1.2414, Tr_acc: 54.686118479221925, val_ac: 54.02061855670103
2025-02-25 23:51:09,827 - INFO - Tr_Loss: 1.1718, val_loss: 1.2366, Tr_acc: 54.81874447391689, val_ac: 53.81443298969072
2025-02-25 23:51:10,212 - INFO - Tr_Loss: 1.1546, val_loss: 1.2320, Tr_acc: 56.89655172413793, val_ac: 53.81443298969072
2025-02-25 23:51:10,588 - INFO - Tr_Loss: 1.1479, val_loss: 1.2271, Tr_acc: 56.89655172413793, val_ac: 54.123711340206185
2025-02-25 23:51:11,003 - INFO - Tr_Loss: 1.1572, val_loss: 1.2226, Tr_acc: 56.71971706454465, val_ac: 54.123711340206185
2025-02-25 23:51:11,396 - INFO - Tr_Loss: 1.1559, val_loss: 1.2183, Tr_acc: 55.39345711759505, val_ac: 54.123711340206185
2025-02-25 23:51:11,772 - INFO - Tr_Loss: 1.1380, val_loss: 1.2139, Tr_acc: 56.49867374005305, val_ac: 54.123711340206185
2025-02-25 23:51:12,156 - INFO - Tr_Loss: 1.1257, val_loss: 1.2093, Tr_acc: 58.17860300618921, val_ac: 54.43298969072165
2025-02-25 23:51:12,531 - INFO - Tr_Loss: 1.1331, val_loss: 1.2052, Tr_acc: 55.96816976127321, val_ac: 54.63917525773196
2025-02-25 23:51:13,041 - INFO - Tr_Loss: 1.1180, val_loss: 1.2010, Tr_acc: 58.09018567639257, val_ac: 55.05154639175258
2025-02-25 23:51:13,513 - INFO - Tr_Loss: 1.1230, val_loss: 1.1971, Tr_acc: 57.780725022104335, val_ac: 55.25773195876289
2025-02-25 23:51:14,036 - INFO - Tr_Loss: 1.0931, val_loss: 1.1930, Tr_acc: 58.44385499557913, val_ac: 55.4639175257732
2025-02-25 23:51:14,546 - INFO - Tr_Loss: 1.1049, val_loss: 1.1888, Tr_acc: 58.17860300618921, val_ac: 55.876288659793815
2025-02-25 23:51:15,006 - INFO - Tr_Loss: 1.1060, val_loss: 1.1849, Tr_acc: 57.20601237842617, val_ac: 55.97938144329897
2025-02-25 23:51:15,472 - INFO - Tr_Loss: 1.1016, val_loss: 1.1807, Tr_acc: 58.39964633068082, val_ac: 56.18556701030928
2025-02-25 23:51:15,908 - INFO - Tr_Loss: 1.0826, val_loss: 1.1773, Tr_acc: 59.06277630415561, val_ac: 56.28865979381443
2025-02-25 23:51:16,353 - INFO - Tr_Loss: 1.0852, val_loss: 1.1735, Tr_acc: 59.328028293545536, val_ac: 56.597938144329895
2025-02-25 23:51:16,758 - INFO - Tr_Loss: 1.0674, val_loss: 1.1695, Tr_acc: 59.99115826702034, val_ac: 56.90721649484536
2025-02-25 23:51:17,223 - INFO - Tr_Loss: 1.0657, val_loss: 1.1653, Tr_acc: 59.41644562334218, val_ac: 56.8041237113402
2025-02-25 23:51:17,605 - INFO - Tr_Loss: 1.0759, val_loss: 1.1618, Tr_acc: 59.01856763925729, val_ac: 57.21649484536083
2025-02-25 23:51:18,050 - INFO - Tr_Loss: 1.0633, val_loss: 1.1585, Tr_acc: 59.41644562334218, val_ac: 56.90721649484536
2025-02-25 23:51:18,564 - INFO - Tr_Loss: 1.0610, val_loss: 1.1548, Tr_acc: 60.52166224580018, val_ac: 57.01030927835052
2025-02-25 23:51:19,124 - INFO - Tr_Loss: 1.0588, val_loss: 1.1513, Tr_acc: 59.814323607427056, val_ac: 57.31958762886598
2025-02-25 23:51:19,622 - INFO - Tr_Loss: 1.0552, val_loss: 1.1477, Tr_acc: 61.0079575596817, val_ac: 57.93814432989691
2025-02-25 23:51:20,033 - INFO - Tr_Loss: 1.0504, val_loss: 1.1445, Tr_acc: 61.80371352785146, val_ac: 57.7319587628866
2025-02-25 23:51:20,469 - INFO - Tr_Loss: 1.0261, val_loss: 1.1410, Tr_acc: 61.759504862953136, val_ac: 57.7319587628866
2025-02-25 23:51:20,906 - INFO - Tr_Loss: 1.0279, val_loss: 1.1378, Tr_acc: 62.20159151193634, val_ac: 57.83505154639175
2025-02-25 23:51:21,368 - INFO - Tr_Loss: 1.0237, val_loss: 1.1349, Tr_acc: 61.53846153846154, val_ac: 57.93814432989691
2025-02-25 23:51:21,811 - INFO - Tr_Loss: 1.0133, val_loss: 1.1317, Tr_acc: 61.8921308576481, val_ac: 57.7319587628866
2025-02-25 23:51:22,271 - INFO - Tr_Loss: 1.0155, val_loss: 1.1289, Tr_acc: 62.51105216622458, val_ac: 57.93814432989691
2025-02-25 23:51:22,692 - INFO - Tr_Loss: 1.0144, val_loss: 1.1257, Tr_acc: 63.48364279398762, val_ac: 57.83505154639175
2025-02-25 23:51:23,168 - INFO - Tr_Loss: 1.0061, val_loss: 1.1227, Tr_acc: 63.70468611847922, val_ac: 58.350515463917525
2025-02-25 23:51:23,582 - INFO - Tr_Loss: 0.9973, val_loss: 1.1194, Tr_acc: 64.67727674624226, val_ac: 58.45360824742268
2025-02-25 23:51:24,031 - INFO - Tr_Loss: 0.9931, val_loss: 1.1166, Tr_acc: 63.92572944297082, val_ac: 58.45360824742268
2025-02-25 23:51:24,439 - INFO - Tr_Loss: 0.9726, val_loss: 1.1138, Tr_acc: 64.14677276746242, val_ac: 58.55670103092783
2025-02-25 23:51:24,953 - INFO - Tr_Loss: 0.9762, val_loss: 1.1107, Tr_acc: 64.9867374005305, val_ac: 58.76288659793814
2025-02-25 23:51:25,466 - INFO - Tr_Loss: 0.9749, val_loss: 1.1078, Tr_acc: 63.793103448275865, val_ac: 58.65979381443299
2025-02-25 23:51:25,907 - INFO - Tr_Loss: 0.9774, val_loss: 1.1053, Tr_acc: 62.86472148541114, val_ac: 58.55670103092783
2025-02-25 23:51:26,345 - INFO - Tr_Loss: 0.9725, val_loss: 1.1024, Tr_acc: 64.63306808134395, val_ac: 58.865979381443296
2025-02-25 23:51:26,794 - INFO - Tr_Loss: 0.9630, val_loss: 1.0993, Tr_acc: 64.19098143236074, val_ac: 58.65979381443299
2025-02-25 23:51:27,233 - INFO - Tr_Loss: 0.9570, val_loss: 1.0967, Tr_acc: 65.03094606542882, val_ac: 58.65979381443299
2025-02-25 23:51:27,693 - INFO - Tr_Loss: 0.9381, val_loss: 1.0939, Tr_acc: 65.69407603890363, val_ac: 58.96907216494845
2025-02-25 23:51:28,103 - INFO - Tr_Loss: 0.9452, val_loss: 1.0910, Tr_acc: 66.57824933687003, val_ac: 59.48453608247423
2025-02-25 23:51:28,509 - INFO - Tr_Loss: 0.9339, val_loss: 1.0885, Tr_acc: 65.69407603890363, val_ac: 59.48453608247423
2025-02-25 23:51:28,901 - INFO - Tr_Loss: 0.9342, val_loss: 1.0864, Tr_acc: 66.0919540229885, val_ac: 59.69072164948454
2025-02-25 23:51:29,324 - INFO - Tr_Loss: 0.9362, val_loss: 1.0841, Tr_acc: 65.82670203359858, val_ac: 60.0
2025-02-25 23:51:29,773 - INFO - Tr_Loss: 0.9378, val_loss: 1.0823, Tr_acc: 65.56145004420867, val_ac: 59.79381443298969
2025-02-25 23:51:30,157 - INFO - Tr_Loss: 0.9293, val_loss: 1.0800, Tr_acc: 65.56145004420867, val_ac: 59.79381443298969
2025-02-25 23:51:30,583 - INFO - Tr_Loss: 0.9196, val_loss: 1.0777, Tr_acc: 65.91511936339522, val_ac: 59.69072164948454
2025-02-25 23:51:30,997 - INFO - Tr_Loss: 0.9156, val_loss: 1.0756, Tr_acc: 67.1971706454465, val_ac: 59.896907216494846
2025-02-25 23:51:31,477 - INFO - Tr_Loss: 0.9168, val_loss: 1.0733, Tr_acc: 66.0919540229885, val_ac: 60.103092783505154
2025-02-25 23:51:31,879 - INFO - Tr_Loss: 0.9073, val_loss: 1.0710, Tr_acc: 67.37400530503979, val_ac: 60.103092783505154
2025-02-25 23:51:32,336 - INFO - Tr_Loss: 0.9068, val_loss: 1.0691, Tr_acc: 66.57824933687003, val_ac: 60.103092783505154
2025-02-25 23:51:32,745 - INFO - Tr_Loss: 0.8991, val_loss: 1.0671, Tr_acc: 67.59504862953139, val_ac: 59.69072164948454
2025-02-25 23:51:32,746 - INFO - Saving trained model and training results...
2025-02-25 23:51:33,392 - INFO - Starting model evaluation...
2025-02-25 23:51:33,422 - INFO - Test Loss: 1.0265
2025-02-25 23:51:33,422 - INFO - Test Accuracy: 63.20%
2025-02-25 23:51:33,422 - INFO - ======== Model Training Completed! ========
