2025-02-23 09:18:57,003 - INFO - ======== Starting Model Training ========
2025-02-23 09:18:57,003 - INFO - Loading dataset...
2025-02-23 09:18:57,731 - INFO - Dataset loaded successfully!
2025-02-23 09:18:57,731 - INFO - Initializing the model...
2025-02-23 09:18:57,876 - INFO - Model initialized with 1,077,445 trainable parameters.
2025-02-23 09:18:57,879 - INFO - Model Architecture: 
MobileNetV2ForCIFAR8M(
  (mobilenet_v2): MobileNetV2(
    (features): Sequential(
      (0): Conv2dNormActivation(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (classifier): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=2048, out_features=512, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=512, out_features=5, bias=True)
    )
  )
)
2025-02-23 09:18:57,879 - INFO - Starting training for 15 epochs...
2025-02-23 09:19:00,868 - INFO - Tr_Loss: 1.2697, val_loss: 1.1117, Tr_acc: 50.20116227089852, val_ac: 57.708333333333336
2025-02-23 09:19:02,528 - INFO - Tr_Loss: 0.8118, val_loss: 0.9315, Tr_acc: 71.21144389807779, val_ac: 64.16666666666667
2025-02-23 09:19:04,179 - INFO - Tr_Loss: 0.6055, val_loss: 0.8850, Tr_acc: 80.50961108627627, val_ac: 65.83333333333333
2025-02-23 09:19:05,828 - INFO - Tr_Loss: 0.4334, val_loss: 0.8818, Tr_acc: 86.54447921323201, val_ac: 64.89583333333333
2025-02-23 09:19:07,465 - INFO - Tr_Loss: 0.3024, val_loss: 0.8769, Tr_acc: 92.13232007152436, val_ac: 66.77083333333333
2025-02-23 09:19:09,124 - INFO - Tr_Loss: 0.2005, val_loss: 0.8930, Tr_acc: 96.11086276262851, val_ac: 67.08333333333333
2025-02-23 09:19:10,783 - INFO - Tr_Loss: 0.1351, val_loss: 0.9147, Tr_acc: 98.1671881984801, val_ac: 66.97916666666667
2025-02-23 09:19:12,442 - INFO - Tr_Loss: 0.0887, val_loss: 0.9689, Tr_acc: 99.06124273580689, val_ac: 66.97916666666667
2025-02-23 09:19:14,106 - INFO - Tr_Loss: 0.0640, val_loss: 1.0300, Tr_acc: 99.50827000447028, val_ac: 67.08333333333333
2025-02-23 09:19:15,758 - INFO - Tr_Loss: 0.0434, val_loss: 1.0613, Tr_acc: 99.73178363880197, val_ac: 67.1875
2025-02-23 09:19:17,433 - INFO - Tr_Loss: 0.0326, val_loss: 1.0624, Tr_acc: 99.95529727313367, val_ac: 68.125
2025-02-23 09:19:19,128 - INFO - Tr_Loss: 0.0271, val_loss: 1.0901, Tr_acc: 99.91059454626732, val_ac: 67.60416666666667
2025-02-23 09:19:20,805 - INFO - Tr_Loss: 0.0198, val_loss: 1.1258, Tr_acc: 100.0, val_ac: 67.8125
2025-02-23 09:19:22,464 - INFO - Tr_Loss: 0.0153, val_loss: 1.1483, Tr_acc: 100.0, val_ac: 67.1875
2025-02-23 09:19:24,125 - INFO - Tr_Loss: 0.0126, val_loss: 1.1863, Tr_acc: 100.0, val_ac: 67.70833333333333
2025-02-23 09:19:24,125 - INFO - Saving trained model and training results...
2025-02-23 09:19:27,492 - INFO - Starting model evaluation...
2025-02-23 09:19:27,574 - INFO - Test Loss: 0.7793
2025-02-23 09:19:27,574 - INFO - Test Accuracy: 72.00%
2025-02-23 09:19:27,574 - INFO - ======== Model Training Completed! ========
