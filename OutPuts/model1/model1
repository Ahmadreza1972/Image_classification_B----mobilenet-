2025-02-25 23:57:56,255 - INFO - ======== Starting Model Training ========
2025-02-25 23:57:56,255 - INFO - Loading dataset...
2025-02-25 23:57:57,006 - INFO - Dataset loaded successfully!
2025-02-25 23:57:57,006 - INFO - Initializing the model...
2025-02-25 23:57:57,089 - INFO - Model initialized with 1,107,141 trainable parameters.
2025-02-25 23:57:57,092 - INFO - Model Architecture: 
MobileNetV2ForCIFAR8M(
  (mobilenet_v2): MobileNetV2(
    (features): Sequential(
      (0): Conv2dNormActivation(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (classifier): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=2048, out_features=512, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.7, inplace=False)
      (4): Linear(in_features=512, out_features=5, bias=True)
    )
  )
)
2025-02-25 23:57:57,094 - INFO - Starting training for 25 epochs...
2025-02-25 23:57:57,876 - INFO - Tr_Loss: 1.4939, val_loss: 1.3329, Tr_acc: 34.68931604827895, val_ac: 50.104166666666664
2025-02-25 23:57:58,298 - INFO - Tr_Loss: 1.2012, val_loss: 1.1599, Tr_acc: 56.59365221278498, val_ac: 59.479166666666664
2025-02-25 23:57:58,717 - INFO - Tr_Loss: 1.0354, val_loss: 1.0505, Tr_acc: 64.01430487259722, val_ac: 63.125
2025-02-25 23:57:59,145 - INFO - Tr_Loss: 0.9005, val_loss: 0.9786, Tr_acc: 68.88690210102816, val_ac: 65.52083333333333
2025-02-25 23:57:59,583 - INFO - Tr_Loss: 0.7847, val_loss: 0.9289, Tr_acc: 73.80420205632544, val_ac: 67.1875
2025-02-25 23:58:00,010 - INFO - Tr_Loss: 0.6929, val_loss: 0.8957, Tr_acc: 78.54269110415736, val_ac: 68.33333333333333
2025-02-25 23:58:00,442 - INFO - Tr_Loss: 0.6283, val_loss: 0.8697, Tr_acc: 79.57085382208315, val_ac: 69.0625
2025-02-25 23:58:00,861 - INFO - Tr_Loss: 0.5593, val_loss: 0.8504, Tr_acc: 82.3871256146625, val_ac: 68.85416666666667
2025-02-25 23:58:01,277 - INFO - Tr_Loss: 0.4956, val_loss: 0.8376, Tr_acc: 85.87393831023692, val_ac: 69.79166666666667
2025-02-25 23:58:01,665 - INFO - Tr_Loss: 0.4320, val_loss: 0.8311, Tr_acc: 88.19848010728654, val_ac: 69.58333333333333
2025-02-25 23:58:02,080 - INFO - Tr_Loss: 0.3907, val_loss: 0.8268, Tr_acc: 89.22664282521234, val_ac: 69.6875
2025-02-25 23:58:02,489 - INFO - Tr_Loss: 0.3415, val_loss: 0.8288, Tr_acc: 91.37237371479661, val_ac: 70.10416666666667
2025-02-25 23:58:02,896 - INFO - Tr_Loss: 0.3055, val_loss: 0.8263, Tr_acc: 92.62405006705409, val_ac: 70.41666666666667
2025-02-25 23:58:03,302 - INFO - Tr_Loss: 0.2679, val_loss: 0.8310, Tr_acc: 93.74161823871256, val_ac: 70.0
2025-02-25 23:58:03,711 - INFO - Tr_Loss: 0.2472, val_loss: 0.8365, Tr_acc: 94.54626732230666, val_ac: 70.3125
2025-02-25 23:58:04,147 - INFO - Tr_Loss: 0.2040, val_loss: 0.8385, Tr_acc: 96.06616003576218, val_ac: 69.6875
2025-02-25 23:58:04,556 - INFO - Tr_Loss: 0.1850, val_loss: 0.8464, Tr_acc: 96.24497094322754, val_ac: 70.10416666666667
2025-02-25 23:58:04,970 - INFO - Tr_Loss: 0.1623, val_loss: 0.8540, Tr_acc: 97.5860527492177, val_ac: 69.89583333333333
2025-02-25 23:58:05,390 - INFO - Tr_Loss: 0.1413, val_loss: 0.8627, Tr_acc: 98.12248547161377, val_ac: 69.89583333333333
2025-02-25 23:58:05,795 - INFO - Tr_Loss: 0.1242, val_loss: 0.8716, Tr_acc: 98.43540455967813, val_ac: 69.58333333333333
2025-02-25 23:58:06,222 - INFO - Tr_Loss: 0.1149, val_loss: 0.8755, Tr_acc: 98.12248547161377, val_ac: 69.79166666666667
2025-02-25 23:58:06,631 - INFO - Tr_Loss: 0.0985, val_loss: 0.8839, Tr_acc: 98.9718372820742, val_ac: 70.20833333333333
2025-02-25 23:58:07,053 - INFO - Tr_Loss: 0.0878, val_loss: 0.8985, Tr_acc: 99.15064818953957, val_ac: 70.0
2025-02-25 23:58:07,469 - INFO - Tr_Loss: 0.0784, val_loss: 0.9090, Tr_acc: 99.37416182387126, val_ac: 70.0
2025-02-25 23:58:07,885 - INFO - Tr_Loss: 0.0693, val_loss: 0.9177, Tr_acc: 99.28475637013858, val_ac: 70.0
2025-02-25 23:58:07,885 - INFO - Saving trained model and training results...
2025-02-25 23:58:08,290 - INFO - Starting model evaluation...
2025-02-25 23:58:08,318 - INFO - Test Loss: 0.6063
2025-02-25 23:58:08,318 - INFO - Test Accuracy: 78.40%
2025-02-25 23:58:08,318 - INFO - ======== Model Training Completed! ========
